<!DOCTYPE html><html lang="en"><head><title>St Etienne talk</title><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><link rel="stylesheet" href="node_modules/reveal.js/css/reveal.css"><link rel="stylesheet" href="css/djs.css"><!-- Used for code syntax highlighting --><link rel="stylesheet" href="node_modules/reveal.js/lib/css/zenburn.css"><script src="js/exports.js"></script></head><body><div class="reveal"><div class="slides"><section data-transition="none"><h1>Generative Modelling with Empirical Distributions</h1><p>Ambrish Rawat, Mathieu Sinn</p><p>IBM Research Dublin</p></section><section data-transition="none"><h3>Why do we care about Generative Modelling?</h3><ul><li class="fragment">It resonates with the "create to understand" school of thought</li><figure class="fragment"><img class="plain" src="img/physics.jpg" align="centre" width="50%" border="None"><img class="plain" src="img/LDA.png" align="centre" width="50%" border="None"></figure><li class="fragment">Wide range of applications have benefited from it </li><p><span class="fragment">... Speech Synthesis, Topic Modelling, Population Genetics ...</span></p></ul></section><section data-transition="none"><h3>How do we approach it?</h3><p class="fragment">Let's take an example<figure class="fragment"><img class="plain" src="img/gm1.jpg" align="centre" width="40%" border="None"></figure></p><div style="width: 100%; position: absolute; left: 0;">\begin{align}

\end{align}
</div></section><section data-transition="none"> <h3>How do we approach it?</h3><p>Let's take an example<figure><img class="plain" src="img/gm2.jpg" align="centre" width="40%" border="None"></figure></p><div style="width: 100%; position: absolute; left: 0;">\begin{align}
  z_n &\sim \text{Multinomial}(z_n|\pi)
\end{align}
</div></section><section data-transition="none"> <h3>How do we approach it?</h3><p>Let's take an example<figure><img class="plain" src="img/gm3.jpg" align="centre" width="40%" border="None"></figure></p><div style="width: 100%; position: absolute; left: 0;">\begin{align}
  z_n &\sim \text{Multinomial}(z_n|\pi)\\
  x_n &\sim \mathcal{N}(\mu_k,\Sigma_k)
\end{align}    
</div></section><section data-transition="none"> <h3>How do we approach it?</h3><p>Let's take an example<figure><img class="plain" src="img/gm3.jpg" align="centre" width="40%" border="None"></figure></p><div style="width: 100%; position: absolute; left: 0;">\begin{align}
  z_n &\sim \text{Multinomial}(z_n|\pi)\\
  x_n &\sim \mathcal{N}(\mu_k,\Sigma_k)
\end{align}
Maximise the log likelihood with respect to observations 
</div></section><section data-transition="none"> <h3>How do we evaluate our model?</h3><p> <strong>Strategy 1: </strong>Try to explain some held out data<figure><img class="plain" src="img/gm4.jpg" align="centre" width="40%" border="None"></figure></p><p class="fragment">...compute log likelihood of test set...</p></section><section data-transition="none"> <h3>How do we evaluate our model?</h3><p> <strong>Strategy 2: </strong>Generate samples and compare them<figure><img class="plain" src="img/gm5.jpg" align="centre" width="40%" border="None"></figure></p><p class="fragment">...some way to measure similarity between points...</p></section><section data-transition="none"> <h3>How do we evaluate our model?</h3><p> <strong>Strategy 2: </strong>Generate samples and compare them<figure><img class="plain" src="img/gm6.jpg" align="centre" width="40%" border="None"></figure></p><p> <strong>Do we really need an explicit distribution for comparison?</strong></p></section><section data-transition="none"> <p> ... leads us to <strong>Implicit Models</strong></p></section><section data-transition="none"> <h3>What are Implicit Models?</h3><figure><img class="plain" src="img/gm6.jpg" align="left" width="40%" border="None"></figure><div style="width: 30%; position: absolute; left: 65%;"><p>$X_{data} \sim P_X$</p><p class="fragment" data-fragment-index="2">$z \sim P_Z, g_{\theta}(z) $</p><p class="fragment" data-fragment-index="3">$X_{gen} \sim P^{(g)}$</p><p class="fragment" data-fragment-index="4">Compare: $X_{gen},X_{data}$</p></div></section><section data-transition="none"> <h3>The case of Implicit Models</h3><ul><li class="fragment">How do we learn them?<ul><li class="fragment">No analytical distribution, so no likelihood</li><li class="fragment">Where do we get the learning signal from?</li></ul></li><li class="fragment">How do we evaluate them?<ul><li class="fragment">Only samples available</li><li class="fragment">Generate similar samples but not the exact same</li></ul></li><li class="fragment">Tons of applications<ul><li class="fragment">..image completion, super resolution, video-frame prediction, texture synthesis ... </li></ul></li></ul><p class="fragment">Popular paradigm: <strong>GANs, VAEs!</strong></p></section><section data-transition="none"> <h3>How do we learn Implicit Models?</h3><figure><img class="plain" src="img/gm6.jpg" align="left" width="40%" border="None"></figure><div style="width: 30%; position: absolute; left: 65%;"><p>$X_{data}, z\sim P_Z,$</p><p>and $g_{\theta}(z)$</p><p class="fragment" data-fragment-index="2">Moment Matching?</p><p class="fragment" data-fragment-index="3">Density Difference?</p><p class="fragment" data-fragment-index="3">Density Ratio?</p></div></section><section data-transition="none"> <h3>What's the MMD approach?</h3><figure><img class="plain" src="img/gm6.jpg" align="left" width="40%" border="None"></figure><div style="width: 30%; position: absolute; left: 65%;"><p>$X_{data}, z\sim P_Z,$</p><p>and $g_{\theta}(z)$</p><p class="fragment" data-fragment-index="2">Two Sample Test</p><p class="fragment" data-fragment-index="3">${K_\text{MMD}}(X_{data},X_{gen})$</p><p class="fragment" data-fragment-index="3">minimise ${K_\text{MMD}}$</p></div></section><section data-transition="none"> <h3>What's the GAN approach?</h3><figure><img class="plain" src="img/gm6.jpg" align="left" width="40%" border="None"></figure><div style="width: 30%; position: absolute; left: 65%;"><p>$X_{data}, z\sim P_Z,$</p><p>and $g_{\theta}(z)$</p><p class="fragment" data-fragment-index="2">Learn the comparison function as well</p><p class="fragment" data-fragment-index="3"><strong>...discriminator... ($d$)</strong></p></div></section><section data-transition="none"> <h3>What are the challenges in the GAN approach?</h3><p class="fragment">$V(d,g) := \mathbb{E}\big[\log(d(X))\big]+ \mathbb{E}\big[\log(1-d(g(Z))) \big]$</p><ul><li class="fragment">It has a min-max objective (not optimisation friendly)</li><li class="fragment">No principed way to train</li><li class="fragment">No guarantee of learning a distribution (reproduce training data?)</li><li class="fragment">An optimal discriminator could yield vanishing gradients</li></ul><p class="fragment">$d^\ast(x) = \frac{p(x)}{p(x) + p^{(g)}(x)}$</p></section><section data-transition="none"> <h3>...a closer look at optimal $d$</h3><p>$d^\ast(x) = \frac{p(x)}{p(x) + p^{(g)}(x)}$</p></section><section data-transition="none"> <h3>...the emprirical case of optimal $d$</h3><p>$d_n^\ast(x) = \frac{\sum_{i=1}^n \mathbb{I}(X_i=x) }{ \sum_{i=1}^n \mathbb{I}(X_i=x) + \sum_{i=1}^n \mathbb{I}(g(Z_i)=x) }$</p></section><section data-transition="none"> <h3>...the smoothed emprirical case of optimal $d$</h3><p>$d_n^\ast(x) = \frac{ \sum_{i=1}^n p^{(\epsilon)}(x-X_i)}{\sum_{i=1}^n p^{(\epsilon)}(x-X_i) +  \sum_{i=1}^n p^{(\epsilon)}(x-g(Z_i))}$</p></section><section data-transition="none"> <h3>So what can we do with this?</h3><div style="width: 100%; position: absolute; left: 0;">\begin{align}
  \hat{p}_{n,\sigma}(x) &:= \frac{1}{\sigma^k n} \sum_{i=1}^n  K\left(\frac{x-X_i}{\sigma}\right)\\
  \hat{p}_{n,\sigma}^{(\theta)}(x) &:= \frac{1}{\sigma^k n} \sum_{i=1}^n   K\left(\frac{x-g_\theta(Z_i)}{\sigma}\right)      
\end{align}


with $K = p^{(\epsilon)}$ we get the a kernel estimate of the density ratio
</div></section><section data-transition="none"> <h3>Our proposed objective function</h3><div style="width: 100%; position: absolute; left: 0;">\begin{align}
  K_n(\theta, \sigma, \varphi) &:= \frac{1}{n} \sum_{i=1}^n \log \frac{\hat{p}_{n,\sigma}(X_i)\,+\, \varphi}{\hat{p}_{n,\sigma}(X_i) \,+\, \hat{p}_{n,\sigma}^{(\theta)}(X_i)\,+\,2 \varphi}\\
  + & \frac{1}{n} \sum_{i=1}^n \log \frac{\hat{p}_{n,\sigma}^{(\theta)}(g_\theta(Z_i))\,+\, \varphi}{\hat{p}_{n,\sigma}(g_\theta(Z_i))\,+\, \hat{p}_{n,\sigma}^{(\theta)}(g_\theta(Z_i))\,+\,2 \varphi}\\
\end{align}

...some desirable assymptotic properties...
</div></section><section data-transition="none"><h3>A toy example</h3><figure><img class="plain" src="img/unrolled1.png" align="centre" width="100%" border="None"></figure></section><section data-transition="none"><h3>Not very exciting, but this can generate digits!</h3><figure><img class="plain" src="img/mnist.png" align="centre" width="60%" border="None"></figure></section><section data-transition="none"><h3>How do we scale this to coloured images?</h3></section><section data-transition="none"><h3>How do we scale this to coloured images?</h3><div style="width: 100%; position: absolute; left: 0;">\begin{align}
  \hat{p}_{n,\sigma}^{(\psi)}(x) \,&:=\, \frac{1}{n} \sum_{i=1}^n  K\left(\frac{f_\psi(x)-f_\psi(X_i)}{\sigma}\right)\\
  \hat{p}_{n,\sigma}^{(\theta,\psi)}(x) \,&:=\, \frac{1}{n} \sum_{i=1}^n   K\left(\frac{f_\psi(x)-f_\psi(g_\theta(Z_i))}{\sigma}\right)\\
\end{align}
$\text{min}_\theta\text{max}_\psi K_n(\psi,\theta, \sigma, \varphi)$
</div></section><section data-transition="none"><h3>Sheets of CIFAR and CelebA</h3><figure><img class="plain" src="img/colour.png" align="centre" width="80%" border="None"></figure></section><section data-transition="none"> <h3>How do we evaluate Implicit Models?</h3><ul><li class="fragment">How does a classifier perceive the generative images?</li></ul><figure class="fragment"><img class="plain" src="img/evaluate.png" align="centre" width="60%" border="None"></figure><p class="fragment">...expected entropy, inception score, distance from training set...</p></section><section data-transition="none"> <h3>What's cooking in the latent space?</h3><figure class="fragment"><img class="plain" src="img/latent1.png" align="centre" width="60%" border="None"></figure></section><section data-transition="none"> <h3>What's cooking in the latent space?</h3><figure><img class="plain" src="img/latent12.png" align="centre" width="60%" border="None"></figure></section><section data-transition="none"> <h3>What's cooking in the latent space?</h3><figure><img class="plain" src="img/latent2.png" align="centre" width="60%" border="None"></figure></section><section data-transition="none"> <h3>What's cooking in the latent space?</h3><figure><img class="plain" src="img/latent3.png" align="centre" width="60%" border="None"></figure></section><section data-transition="none"><h3> ... remaining challenges</h3><ul><li>With introduction of $f_{\psi}$ we are back to square one for balacing discriminator and generator training.</li><li>(the good old one) How to choose the right kernel?</li><li>What is the effect of the regulariser ($\varphi$)?</li><li>Can we make use of any dynamics in the latent space for useful generation?</li><li>...</li></ul><a class="fragment" href="https://arxiv.org/abs/1705.09199">Non-parametric estimation of Jensen-Shannon Divergence in Generative Adversrial Network Training (arxiv:1705.09199)</a></section><section data-transition="none"><h3> ...other ongoing research at IBM</h3><ul><li>Bayesian Deep Learning</li><li>Adversarial ML and Security of AI</li><li>Open World Visual Recognition</li></ul><figure><img class="plain" src="img/team.png" align="centre" width="60%" border="None"></figure></section></div></div><script src="node_modules/reveal.js/lib/js/head.min.js"></script><script src="node_modules/reveal.js/js/reveal.js"></script><script src="js/init.js"></script></body></html>